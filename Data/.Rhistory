library(plotrix)
dev.copy(pdf,'ESSS2_barplot_n9.pdf')
dev.off()
#means and SDs
condition.mean.sd <- summaryBy(target.form.mean ~  prime.condition + used.target.condition + prime.form, FUN=c(mean,sd), data=subjectmeans); condition.mean.sd
write.table(condition.mean.sd,"used.target.condition_condition.mean.sd_N=32", col.names=NA)
library(lme4)
library(languageR)
#plot(target.answer~prime.form)
analysisnorandom <- lmer(target.form ~ prime.condition*prime.form*used.target.condition + (1|participant) + (1|target.item), data=DOPO, family="binomial")
summary(analysisnorandom)
str(DOPO)
stripchart(prime.form~target.form, method="jitter", ylab="Target Answers", xlab="Prime Forms")
library(lme4)
library(languageR)
str(DOPO)
mixedeffects<-lmer(target.form~prime.form+prime.condition+(1|participant)+(1|target.item),DOPO)
mixedeffects
pvals.fnc(mixedeffects)
#standard errors and all
library(ggplot2)
## Summarizes data.
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
conf.interval=.95, .drop=TRUE) {
require(plyr)
# New version of length which can handle NA's: if na.rm==T, don't count them
length2 <- function (x, na.rm=FALSE) {
if (na.rm) sum(!is.na(x))
else       length(x)
}
# This is does the summary; it's not easy to understand...
datac <- ddply(data, groupvars, .drop=.drop,
.fun= function(xx, col, na.rm) {
c( N    = length2(xx[,col], na.rm=na.rm),
mean = mean   (xx[,col], na.rm=na.rm),
sd   = sd     (xx[,col], na.rm=na.rm)
)
},
measurevar,
na.rm
)
# Rename the "mean" column
datac <- rename(datac, c("mean"=measurevar))
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
summarySE(DOPO, measurevar="targetformDO", groupvars=c("prime.form","prime.condition", "target.condition"), na.rm=FALSE)
# print the current working directory - cwd
getwd()
save.image()
#failed loops (consider later)
#for(i in unique (alldata$kind)) {subset(alldata, kind==i)
#	print}
#for(i in unique (alldata$kind)) {mixedeffects<-lmer(rt~ type + (1|participant)+(1|set),subset(alldata, kind==i))}
# Subset for ANOVA
primestargets <- subset(DOPO, select=c(target.item,prime.condition,prime.form,used.target.condition,targetformDO))
write.table(primestargets,"primestargets_N=64", col.names=NA)
# lightprimeslighttargets
lightprimeslighttargets <- subset(DOPO, prime.condition == "L" & used.target.condition == "L", select=c(prime.condition,prime.form,targetformDO))
head(lightprimeslighttargets)
summary(lightprimeslighttargets)
aov.lightprimeslighttargets = aov(targetformDO~prime.form, data=lightprimeslighttargets)
summary(aov.lightprimeslighttargets)
table(prime.condition,prime.form,used.target.condition, targetformDO)
write.table(lightprimeslighttargets,"lightprimeslighttargets_N=64", col.names=NA)
# nonlightprimeslighttargets
nonlightprimeslighttargets <- subset(DOPO, prime.condition == "NL" & used.target.condition == "L", select=c(prime.condition,prime.form,targetformDO))
summary(nonlightprimeslighttargets)
aov.nonlightprimeslighttargets = aov(targetformDO~prime.form, data=nonlightprimeslighttargets)
summary(aov.nonlightprimeslighttargets)
# nonlightprimesnonlighttargets
nonlightprimesnonlighttargets <- subset(DOPO, prime.condition == "NL" & used.target.condition == "NL", select=c(prime.form,targetformDO))
summary(nonlightprimesnonlighttargets)
aov.nonlightprimesnonlighttargets = aov(targetformDO~prime.form, data=nonlightprimesnonlighttargets)
summary(aov.nonlightprimesnonlighttargets)
# lightprimesnonlighttargets
lightprimesnonlighttargets <- subset(DOPO, prime.condition == "L" & used.target.condition == "NL", select=c(prime.form,targetformDO))
summary(lightprimesnonlighttargets)
aov.lightprimesnonlighttargets = aov(targetformDO~prime.form, data=lightprimesnonlighttargets)
summary(aov.lightprimesnonlighttargets)
aov.DOPO= aov(target.form~prime.condition*prime.form*used.target.condition,data=DOPO)
summary(aov.DOPO)
aov.DOPO.primecondition.primeform= aov(target.form~prime.condition*prime.form,data=DOPO)
summary(aov.DOPO.primecondition.primeform)
#non-light targets
nonlight.targets <- subset(DOPO, used.target.condition=="NL")
head(nonlight.targets)
prozente<-prop.table(table(targetformDO,prime.form, target.form, prime.condition),margin=2)
prozente
summary(nonlight.targets)
aov.nonlight= aov(targetformDO~prime.condition*prime.form,data=nonlight.targets)
summary(aov.nonlight)
#non-light targets after light primes only
nonlight.targets <- subset(DOPO, used.target.condition=="NL")
nonlight.targets.light.primes <- subset(nonlight.targets, prime.condition=="L")
aov.nonlight.targets.light.primes= aov(targetformDO~prime.form,data=nonlight.targets.light.primes)
summary(aov.nonlight.targets.light.primes)
#non-light targets after nonlight primes only
nonlight.targets <- subset(DOPO, used.target.condition=="NL")
nonlight.targets.nonlight.primes <- subset(nonlight.targets, prime.condition=="NL")
aov.nonlight.targets.nonlight.primes= aov(targetformDO~prime.form,data=nonlight.targets.light.primes)
summary(aov.nonlight.targets.nonlight.primes)
#light targets
light.targets <- subset(DOPO, used.target.condition=="L")
head(light.targets)
prozente<-prop.table(table(targetformDO,prime.form, prime.condition),margin=2)
prozente
summary(light.targets)
aov.light= aov(targetformDO~prime.condition*prime.form,data=light.targets)
summary(aov.light)
#light primes
light.primes <- subset(DOPO, prime.condition=="L")
head(light.primes)
aov.light.primes= aov(targetformDO~prime.form*used.target.condition,data=light.primes)
summary(aov.light.primes)
#nonlight primes
nonlight.primes <- subset(DOPO, prime.condition=="NL")
head(nonlight.primes)
aov.nonlight.primes= aov(targetformDO~prime.form*used.target.condition,data=nonlight.primes)
summary(aov.nonlight.primes)
system.time(m.full <- lmer(targetformDO ~ 1 + prime.condition*prime.form.numeric*used.target.condition.numeric + (prime.condition.numeric+prime.form.numeric+used.target.condition.numeric|participant) + (prime.condition.numeric+prime.form.numeric+used.target.condition.numeric|target.item), data=completecases,REML=F))
system.time(m.full <- lmer(targetformDO ~ 1 + prime.condition*prime.form.numeric*used.target.condition.numeric + (prime.condition.numeric+prime.form.numeric+used.target.condition.numeric|participant) + (prime.condition.numeric+prime.form.numeric+used.target.condition.numeric|target.item), data=DOPO,family=binomial))
system.time(m.full <- lmer(targetformDO ~ 1 + prime.condition*prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(prime.condition.numeric|participant) +
(prime.form.numeric|participant) +
(used.target.condition.numeric|participant) +
(1|target.item) +
(prime.condition.numeric|target.item) +
(prime.form.numeric|target.item) +
(used.target.condition.numeric|target.item), data=DOPO,family=binomial))
system.time(m.full <- lmer(targetformDO ~ 1 + prime.condition*prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(prime.condition.numeric|participant) +
(prime.form.numeric|participant) +
(used.target.condition.numeric|participant) +
(1|target.item) +
(prime.condition.numeric|target.item) +
(prime.form.numeric|target.item) +
(used.target.condition.numeric|target.item), data=DOPO,family=binomial))
system.time(m.full <- lmer(targetformDO ~ 1 + prime.condition*prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
system.time(m.full <- glmer(targetformDO ~ 1 + prime.condition*prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
system.time(m.noPrimeCondition <- lmer(targetformDO ~ 1 + prime.condition + prime.condition:(prime.form.numeric*used.target.condition.numeric) +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
system.time(m.noPrimeCondition <- glmer(targetformDO ~ 1 + prime.condition + prime.condition:(prime.form.numeric*used.target.condition.numeric) +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
system.time(m.noPrimeCondition <- glmer(targetformDO ~ 1 + prime.condition + prime.condition:used.target.condition + prime.condition:prime.form.numeric + prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
xtable(anova(m.noPrimeCondition,m.full), digits=3)
anova(m.noPrimeCondition,m.full
anova(m.noPrimeCondition,m.full)
system.time(m.full <- glmer(targetformDO ~ 1 + prime.condition.numeric*prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
system.time(m.noPrimeCondition <- glmer(targetformDO ~ 1 + prime.condition.numeric+ prime.condition.numeric:used.target.condition + prime.condition.numeric:prime.form.numeric + prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
anova(m.noPrimeCondition,m.full)
system.time(m.noPrimeForm <- glmer(targetformDO ~ 1 + prime.form.numeric+ prime.form.numeric:used.target.condition + prime.condition.numeric:prime.form.numeric + prime.condition.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
anova(m.noPrimeForm,m.full)
system.time(m.noPrimeCondition <- glmer(targetformDO ~ 1 + prime.condition.numeric + prime.form.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
anova(m.noPrimeCondition,m.full)
system.time(m.noPrimeForm <- glmer(targetformDO ~ 1 + prime.form.numeric + prime.condition.numeric*used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
anova(m.noPrimeForm,m.full)
system.time(m.noTargetCond <- glmer(targetformDO ~ 1 + prime.form.numeric*prime.condition.numeric + used.target.condition.numeric +
(1|participant) +
anova(m.noPrimeTargetCond,m.full)
system.time(m.noTargetCond <- glmer(targetformDO ~ 1 + prime.form.numeric*prime.condition.numeric + used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
system.time(m.noTargetCond <- glmer(targetformDO ~ 1 + prime.form.numeric*prime.condition.numeric + used.target.condition.numeric +
(1|participant) +
(1|target.item), data=DOPO,family=binomial))
anova(m.noPrimeTargetCond,m.full)
anova(m.noTargetCond,m.full)
m.nocorr <- lmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition + (prime.condition.numeric*prime.form.numeric*used.target.condition.numeric||participant) + (prime.condition.numeric*prime.form.numeric*used.target.condition.numeric||target.item), data=DOPO, family=binomial)
m.nocorr.3way <- lmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition + (prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||participant) + (prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||target.item), data=DOPO, family=binomial)
m.nocorr.3way <- lmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition + (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||participant) + (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||target.item), data=DOPO, family=binomial)
m.nocorr.3way <- glmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition + (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||participant) + (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||target.item), data=DOPO, family=binomial)
m.nocorr.3way.0 <- glmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition - prime.condition:prime.form:used.target.condition (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||participant) + (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||target.item), data=DOPO, family=binomial)
m.nocorr.3way.0 <- glmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition - prime.condition:prime.form:used.target.condition + (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||participant) + (0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||target.item), data=DOPO, family=binomial)
summary(m.nocorr.3way.0)
summary(m.nocorr.3way)
anova(m.nocorr.3way.0,m.nocorr.3way)
m.nocorr.3way <- glmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition +
(prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||participant) +
(0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||target.item), data=DOPO, family=binomial)
m.nocorr.3way.0 <- glmer(target.form ~ 1 + prime.condition*prime.form*used.target.condition -
prime.condition:prime.form:used.target.condition +
(prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||participant) +
(0+prime.condition.numeric:prime.form.numeric:used.target.condition.numeric||target.item), data=DOPO, family=binomial)
anova(m.nocorr.3way.0,m.nocorr.3way)
menorahBurnout <- function(nJews){
meanCandleDuration = 1000
sdCandleVariation = 200
timeToLightOneCandle = 1
shamash = 1
ddtdc = array(0,8)
correctedDdtdc = array(0,8)
for(currentJew in 1:nJews){
if(length(intersect(currentJew,seq(0,nJews,10000))) > 0) {cat(currentJew)}
for(currentNightOfChanukkah in 1:8){
t=0
tLit = array(0,currentNightOfChanukkah)
tExhausted = array(0,currentNightOfChanukkah)
correctedTExhausted = array(0,currentNightOfChanukkah)
for(currentCandle in 1:(currentNightOfChanukkah + shamash)){
t = t+timeToLightOneCandle
tLit[currentCandle] = t
tExhausted[currentCandle] = t + rnorm(1, mean = meanCandleDuration, sd = sdCandleVariation)
correctedTExhausted[currentCandle] = tExhausted[currentCandle] - tLit[currentCandle]
}
# cumulative moving avg for less ram use (even though I'm using loops instead of apply)
if(currentJew == 1){
ddtdc[currentNightOfChanukkah] = max(tExhausted) - min(tExhausted)
correctedDdtdc[currentNightOfChanukkah] = max(correctedTExhausted) - min(correctedTExhausted)
} else {
ddtdc[currentNightOfChanukkah] = ddtdc[currentNightOfChanukkah] + (((max(tExhausted) - min(tExhausted)) - ddtdc[currentNightOfChanukkah]) / currentJew)
correctedDdtdc[currentNightOfChanukkah] = correctedDdtdc[currentNightOfChanukkah] + (((max(correctedTExhausted) - min(correctedTExhausted)) - correctedDdtdc[currentNightOfChanukkah]) / currentJew)
}
par(mfrow=c(1,2))
plot(ddtdc, main="Difference in candle\nexhaustion times.", xlab="Night of Chanukkah", ylab="Maximum difference in exhaustion times")
plot(correctedDdtdc, main="Difference in candle\nburning durations.", xlab="Night of Chanukkah", ylab="Maximum difference in burning times")
return(list("DifferenceInExhaustionTimes" = ddtdc, "DifferenceInBurningDurations" = correctedDdtdc))
}
menorahBurnout(270000) # estimated jewish population in the uk (runtime ~ 3 minutes)
# Eva, April 2016 #
rm(list=ls())
library(doBy)
library(ggplot2)
library(car)
library(lme4)
library(languageR)
library(xtable)
library(reshape2)
library(scales)
#read data in
getwd()
setwd("/Users/evinapatata/GitHub/NOI/Data")
dat <- read.csv("NOI_ALL_RawData.csv")
head(dat)
dat$participant <- as.character(dat$participant)
dat$language <- as.character(dat$language)
dat$participant <- paste(dat$participant,dat$language,sep='_')
unique(dat$participant)
str(dat)
#drop stuff we don't need -- ONLY critical items
dat <- droplevels(subset(dat, dat$category=="E"))
dat <- droplevels(subset(dat, dat$framesetter!=""))
dat <- droplevels(subset(dat, dat$framesetter!=" "))
dat <- droplevels(subset(dat, dat$framesetter!="4"))
dat <- droplevels(subset(dat, dat$framesetter!="na"))
dat <- droplevels(subset(dat, dat$topic!=""))
dat <- droplevels(subset(dat, dat$topic!=" "))
dat <- droplevels(subset(dat, dat$topic!="4"))
dat <- droplevels(subset(dat, dat$topic!="na"))
dat <- droplevels(subset(dat, dat$verb!=""))
dat <- droplevels(subset(dat, dat$verb!=" "))
dat <- droplevels(subset(dat, dat$verb!="4"))
dat <- droplevels(subset(dat, dat$verb!="na"))
dat <- droplevels(subset(dat, dat$verb!="0"))
####subset to verbal####
which(colnames(dat)=="participant")
which(colnames(dat)=="language")
which(colnames(dat)=="item")
which(colnames(dat)=="verbal_framesetter")
which(colnames(dat)=="verbal_Verb")
datV <- dat[c(1:3,9:11)]; head(dat)
write.csv(datV, "NOI_ALL_CleanVerbalData.csv")
str(datV)
datV$Forder <- recode(datV$verbal_framesetter, "'1' = 'Ffirst';
'2' = 'Fmid';
'3' = 'Flast'")
datV$Vorder <- recode(datV$verbal_Verb, "'1' = 'Vfirst';
'2' = 'Vmid';
'3' = 'Vlast'")
datV$Torder <- recode(datV$verbal_topic, "'1' = 'Tfirst';
'2' = 'Tmid';
'3' = 'Tlast'")
#make a verbal_order column
datV$verbal_order <- paste(datV$verbal_framesetter,datV$verbal_topic,datV$verbal_Verb,sep='')
unique(datV$verbal_order)
datV <- droplevels(subset(datV, datV$verbal_order!="NA12"))
datV <- droplevels(subset(datV, datV$verbal_order!="NANANA"))
datV$verbal_order <- recode(datV$verbal_order, "'231' = 'TVF' ;
'123' = 'FTV';
'213' = 'TFV';
'312' = 'VFT';
'321' = 'VTF';
'213' = 'TFV';
'132' = 'FVT'")
#data summaries and chi-square tests
library(plyr)
count(datV, 'verbal_order')
do.call(rbind , by(datV$language, datV$Vorder, summary))
library(MASS)       # load the MASS package
tblALL = table(datV$language, datV$Vorder)
tblALL                 # the contingency table
chisq.test(tblALL)
# Eva, April 2016 #
rm(list=ls())
library(doBy)
library(ggplot2)
library(car)
library(lme4)
library(languageR)
library(xtable)
library(reshape2)
library(scales)
#read data in
getwd()
setwd("/Users/evinapatata/GitHub/NOI/Data")
dat <- read.csv("NOI_AllAction_RawData.csv")
head(dat)
dat$subject <- as.character(dat$subject)
dat$language <- as.character(dat$language)
dat$subject <- paste(dat$subject,dat$language,sep='_')
unique(dat$subject)
str(dat)
#drop stuff we don't need -- ONLY critical items
dat <- droplevels(subset(dat, dat$category=="E"))
dat <- droplevels(subset(dat, dat$framesetter!=""))
dat <- droplevels(subset(dat, dat$framesetter!=" "))
dat <- droplevels(subset(dat, dat$framesetter!="4"))
dat <- droplevels(subset(dat, dat$framesetter!="na"))
dat <- droplevels(subset(dat, dat$topic!=""))
dat <- droplevels(subset(dat, dat$topic!=" "))
dat <- droplevels(subset(dat, dat$topic!="4"))
dat <- droplevels(subset(dat, dat$topic!="na"))
dat <- droplevels(subset(dat, dat$verb!=""))
dat <- droplevels(subset(dat, dat$verb!=" "))
dat <- droplevels(subset(dat, dat$verb!="4"))
dat <- droplevels(subset(dat, dat$verb!="na"))
dat <- droplevels(subset(dat, dat$verb!="0"))
which(colnames(dat)=="subject")
which(colnames(dat)=="language")
which(colnames(dat)=="abbreviation")
which(colnames(dat)=="framesetter")
which(colnames(dat)=="verb")
dat <- dat[c(1:3,9:11)]; head(dat)
write.csv(dat, "NOI_ALL_CleanActionData.csv")
dat$Forder <- recode(dat$framesetter, "'1' = 'Ffirst';
'2' = 'Fmid';
'3' = 'Flast'")
dat$Vorder <- recode(dat$verb, "'1' = 'Vfirst';
'2' = 'Vmid';
'3' = 'Vlast'")
dat$Torder <- recode(dat$topic, "'1' = 'Tfirst';
'2' = 'Tmid';
'3' = 'Tlast'")
str(dat)
#make an action_order column
dat$action_order <- paste(dat$framesetter,dat$topic,dat$verb,sep='')
unique(dat$action_order)
dat$action_order <- recode(dat$action_order, "'231' = 'TVF' ; '123' = 'FTV'; '213' = 'TFV'; '312' = 'VFT'; '321' = 'VTF'; '213' = 'TFV'; '132' = 'FVT'")
dat <- droplevels(subset(dat, dat$action_order!="112"))
dat <- droplevels(subset(dat, dat$action_order!="113"))
#Data summaries and chi-square tests
library(plyr)
count(dat, 'action_order')
do.call(rbind , by(dat$language, dat$Forder, summary))
library(MASS)       # load the MASS package
tblALL = table(dat$language, dat$Vorder)
tblALL                 # the contingency table
chisq.test(tblALL)
str(all)
str(dat)
dat.counts <- with(dat,aggregate(list(Count=Forder),list(order=Forder,language=language),length))
dat.sums <- with(dat.counts,tapply(Count,list(language=language),sum))
dat.counts$Proportion <- with(dat.counts,Count/dat.sums[cbind(language)])
order <- factor(dat.counts$language)
str(dat.counts)
bar <- ggplot(dat.counts, aes(x=language,y=Proportion, fill = order))
dodge <- position_dodge(width=0.9)
bar + geom_bar(stat="identity",position=dodge) +
scale_fill_manual(values=c("#99d8c9", "#2ca25f","#006d2c"))  +
theme_bw()+
theme(axis.text.y = element_text(size=16),
axis.text.x = element_text(size=16),
strip.text.x = element_text(size=20),
axis.title.y = element_text(size=20),
legend.title = element_text(size=14),
legend.text = element_text(size=14),
axis.title.x = element_text(size=20))+
scale_y_continuous(labels=percent, limits = c(0, 1))+
labs(x="", y="Proportion of order for Framesetters", fill="Answer")
bar <- ggplot(dat.counts, aes(x=order,y=Proportion, fill = language))
dodge <- position_dodge(width=0.9)
bar + geom_bar(stat="identity",position=dodge) +
scale_fill_manual(values=c("#99d8c9", "#2ca25f","#006d2c"))  +
theme_bw()+
theme(axis.text.y = element_text(size=16),
axis.text.x = element_text(size=16),
strip.text.x = element_text(size=20),
axis.title.y = element_text(size=20),
legend.title = element_text(size=14),
legend.text = element_text(size=14),
axis.title.x = element_text(size=20))+
scale_y_continuous(labels=percent, limits = c(0, 1))+
labs(x="", y="Proportion of order for Framesetters", fill="Answer")
bar <- ggplot(dat.counts, aes(x=order,y=Proportion, fill = language))
dodge <- position_dodge(width=0.9)
bar + geom_bar(stat="identity",position=dodge) +
scale_fill_manual(values=c("#99d8c9", "#2ca25f","#006d2c"))  +
theme_bw()+
theme(axis.text.y = element_text(size=16),
axis.text.x = element_text(size=16),
strip.text.x = element_text(size=20),
axis.title.y = element_text(size=20),
legend.title = element_text(size=14),
legend.text = element_text(size=14),
axis.title.x = element_text(size=20))+
scale_y_continuous(labels=percent, limits = c(0, 1))+
labs(x="", y="Proportion of order for Framesetters", fill="Language")
plot(tblVlast)
tblVlast                 # the contingency table
# Eva, April 2016 #
rm(list=ls())
library(doBy)
library(ggplot2)
library(car)
library(lme4)
library(languageR)
library(xtable)
library(reshape2)
library(scales)
#read data in
getwd()
setwd("/Users/evinapatata/GitHub/NOI/Data")
dat <- read.csv("NOI_AllAction_RawData.csv")
head(dat)
dat$subject <- as.character(dat$subject)
dat$language <- as.character(dat$language)
dat$subject <- paste(dat$subject,dat$language,sep='_')
unique(dat$subject)
str(dat)
#drop stuff we don't need -- ONLY critical items
dat <- droplevels(subset(dat, dat$category=="E"))
dat <- droplevels(subset(dat, dat$framesetter!=""))
dat <- droplevels(subset(dat, dat$framesetter!=" "))
dat <- droplevels(subset(dat, dat$framesetter!="4"))
dat <- droplevels(subset(dat, dat$framesetter!="na"))
dat <- droplevels(subset(dat, dat$topic!=""))
dat <- droplevels(subset(dat, dat$topic!=" "))
dat <- droplevels(subset(dat, dat$topic!="4"))
dat <- droplevels(subset(dat, dat$topic!="na"))
dat <- droplevels(subset(dat, dat$verb!=""))
dat <- droplevels(subset(dat, dat$verb!=" "))
dat <- droplevels(subset(dat, dat$verb!="4"))
dat <- droplevels(subset(dat, dat$verb!="na"))
dat <- droplevels(subset(dat, dat$verb!="0"))
which(colnames(dat)=="subject")
which(colnames(dat)=="language")
which(colnames(dat)=="abbreviation")
which(colnames(dat)=="framesetter")
which(colnames(dat)=="verb")
dat <- dat[c(1:3,9:11)]; head(dat)
write.csv(dat, "NOI_ALL_CleanActionData.csv")
dat$Forder <- recode(dat$framesetter, "'1' = 'Ffirst';
'2' = 'Fmid';
'3' = 'Flast'")
dat$Vorder <- recode(dat$verb, "'1' = 'Vfirst';
'2' = 'Vmid';
'3' = 'Vlast'")
dat$Torder <- recode(dat$topic, "'1' = 'Tfirst';
'2' = 'Tmid';
'3' = 'Tlast'")
str(dat)
#make an action_order column
dat$action_order <- paste(dat$framesetter,dat$topic,dat$verb,sep='')
unique(dat$action_order)
dat$action_order <- recode(dat$action_order, "'231' = 'TVF' ; '123' = 'FTV'; '213' = 'TFV'; '312' = 'VFT'; '321' = 'VTF'; '213' = 'TFV'; '132' = 'FVT'")
dat <- droplevels(subset(dat, dat$action_order!="112"))
dat <- droplevels(subset(dat, dat$action_order!="113"))
#Data summaries and chi-square tests
library(plyr)
count(dat, 'action_order')
do.call(rbind , by(dat$language, dat$Forder, summary))
library(MASS)       # load the MASS package
tblALL = table(dat$language, dat$Vorder)
tblALL                 # the contingency table
chisq.test(tblALL)
str(dat)
str(dat)
Vlast <- droplevels(subset(dat, Vorder=="Vlast"))
tblVlast = table(Vlast$action_order, Vlast$language)
tblVlast
chisq.test(tblVlast)
